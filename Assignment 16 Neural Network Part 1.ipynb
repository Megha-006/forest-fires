{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f905e2a2",
   "metadata": {},
   "source": [
    "# Forest fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dad25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\megha\\anaconda3\\lib\\site-packages (2.7.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\megha\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53de8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5806c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('D:/Megha/Desktop/DS assignments/Assignment 16 Neural network/forestfires.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0441b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a815f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
       "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
       "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
       "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay',\n",
       "       'monthnov', 'monthoct', 'monthsep', 'size_category'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55e9068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>92.1</td>\n",
       "      <td>111.2</td>\n",
       "      <td>654.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>42</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>91.4</td>\n",
       "      <td>142.4</td>\n",
       "      <td>601.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>39</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>mar</td>\n",
       "      <td>sat</td>\n",
       "      <td>91.7</td>\n",
       "      <td>35.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.1</td>\n",
       "      <td>94.1</td>\n",
       "      <td>232.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>91.6</td>\n",
       "      <td>248.4</td>\n",
       "      <td>753.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>20.4</td>\n",
       "      <td>56</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>93.7</td>\n",
       "      <td>231.1</td>\n",
       "      <td>715.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>64</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>96.1</td>\n",
       "      <td>181.1</td>\n",
       "      <td>671.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>21.6</td>\n",
       "      <td>65</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.0</td>\n",
       "      <td>166.9</td>\n",
       "      <td>752.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>41</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "53    aug  wed  92.1  111.2  654.1   9.6  20.4  42   4.9   0.0  ...         0   \n",
       "100   aug  sun  91.4  142.4  601.4  10.6  19.8  39   5.4   0.0  ...         0   \n",
       "215   mar  sat  91.7   35.8   80.8   7.8  17.0  27   4.9   0.0  ...         0   \n",
       "303   jun  fri  91.1   94.1  232.1   7.1  19.2  38   4.5   0.0  ...         0   \n",
       "426   aug  thu  91.6  248.4  753.8   6.3  20.4  56   2.2   0.0  ...         0   \n",
       "461   aug  sat  93.7  231.1  715.1   8.4  18.9  64   4.9   0.0  ...         0   \n",
       "501   aug  tue  96.1  181.1  671.2  14.3  21.6  65   4.9   0.8  ...         0   \n",
       "508   aug  fri  91.0  166.9  752.6   7.1  25.9  41   3.6   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "53          0         0         0         0         0         0         0   \n",
       "100         0         0         0         0         0         0         0   \n",
       "215         0         0         0         1         0         0         0   \n",
       "303         0         0         1         0         0         0         0   \n",
       "426         0         0         0         0         0         0         0   \n",
       "461         0         0         0         0         0         0         0   \n",
       "501         0         0         0         0         0         0         0   \n",
       "508         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "53          0          small  \n",
       "100         0          small  \n",
       "215         0          large  \n",
       "303         0          small  \n",
       "426         0          small  \n",
       "461         0          small  \n",
       "501         0          small  \n",
       "508         0          small  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c72402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[509 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c399b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='month', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(6,6)})\n",
    "sns.countplot(df['month'],hue=df['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2f24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='day', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['day'],hue=(df['size_category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df969f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='size_category', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3fbb027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[509 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6d45a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0          small  \n",
       "1           1         0          small  \n",
       "2           1         0          small  \n",
       "3           0         0          small  \n",
       "4           0         0          small  \n",
       "..        ...       ...            ...  \n",
       "512         0         0          large  \n",
       "513         0         0          large  \n",
       "514         0         0          large  \n",
       "515         0         0          small  \n",
       "516         0         0          small  \n",
       "\n",
       "[509 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.iloc[:,2:31]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a851a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category_small  \n",
       "0           0         0                    1  \n",
       "1           1         0                    1  \n",
       "2           1         0                    1  \n",
       "3           0         0                    1  \n",
       "4           0         0                    1  \n",
       "..        ...       ...                  ...  \n",
       "512         0         0                    0  \n",
       "513         0         0                    0  \n",
       "514         0         0                    0  \n",
       "515         0         0                    1  \n",
       "516         0         0                    1  \n",
       "\n",
       "[509 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df,drop_first=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d712c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86.2,  26.2,  94.3, ...,   0. ,   0. ,   0. ],\n",
       "       [ 90.6,  35.4, 669.1, ...,   0. ,   1. ,   0. ],\n",
       "       [ 90.6,  43.7, 686.9, ...,   0. ,   1. ,   0. ],\n",
       "       ...,\n",
       "       [ 81.6,  56.7, 665.6, ...,   0. ,   0. ,   0. ],\n",
       "       [ 94.4, 146. , 614.7, ...,   0. ,   0. ,   0. ],\n",
       "       [ 79.5,   3. , 106.7, ...,   1. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.iloc[:,0:28].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6314c6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.iloc[:,28:29].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c1c2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9924c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91. , 166.9, 752.6, ...,   0. ,   0. ,   0. ],\n",
       "       [ 90.1,  82.9, 735.7, ...,   0. ,   0. ,   1. ],\n",
       "       [ 91.7,  33.3,  77.5, ...,   0. ,   0. ,   0. ],\n",
       "       ...,\n",
       "       [ 93.7,  80.9, 685.2, ...,   0. ,   0. ,   1. ],\n",
       "       [ 92. , 203.2, 664.5, ...,   0. ,   0. ,   0. ],\n",
       "       [ 79.5,   3.6,  15.3, ...,   0. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df6a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbcced4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92.1, 207. , 672.6, ...,   0. ,   0. ,   0. ],\n",
       "       [ 95.8, 152. , 624.1, ...,   0. ,   0. ,   0. ],\n",
       "       [ 90.8,  84.7, 376.6, ...,   0. ,   0. ,   0. ],\n",
       "       ...,\n",
       "       [ 92.4, 105.8, 758.1, ...,   0. ,   0. ,   1. ],\n",
       "       [ 94.3,  85.1, 692.3, ...,   0. ,   0. ,   1. ],\n",
       "       [ 92.9, 133.3, 699.6, ...,   0. ,   0. ,   1. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0775db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18a70979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7900be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "scaler.fit(x_test)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "488a194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05682291,  0.84560363,  0.81874851, ..., -0.05307449,\n",
       "        -0.19468147, -0.68634859],\n",
       "       [-0.13401629, -0.43477324,  0.74989172, ..., -0.05307449,\n",
       "        -0.19468147,  1.45698559],\n",
       "       [ 0.20525339, -1.19080529, -1.93185627, ..., -0.05307449,\n",
       "        -0.19468147, -0.68634859],\n",
       "       ...,\n",
       "       [ 0.62934049, -0.4652584 ,  0.54413622, ..., -0.05307449,\n",
       "        -0.19468147,  1.45698559],\n",
       "       [ 0.26886646,  1.39890935,  0.45979683, ..., -0.05307449,\n",
       "        -0.19468147, -0.68634859],\n",
       "       [-2.38167793, -1.64350997, -2.18528186, ..., -0.05307449,\n",
       "        -0.19468147, -0.68634859]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8601f9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2455394 ,  1.68450808,  0.52783736, ...,  0.        ,\n",
       "        -0.11508707, -0.78136183],\n",
       "       [ 0.76555382,  0.75363589,  0.33650151, ...,  0.        ,\n",
       "        -0.11508707, -0.78136183],\n",
       "       [ 0.06283163, -0.38541317, -0.63990311, ...,  0.        ,\n",
       "        -0.11508707, -0.78136183],\n",
       "       ...,\n",
       "       [ 0.28770273, -0.02829674,  0.86514077, ...,  0.        ,\n",
       "        -0.11508707,  1.2798168 ],\n",
       "       [ 0.55473717, -0.37864319,  0.60555522, ...,  0.        ,\n",
       "        -0.11508707,  1.2798168 ],\n",
       "       [ 0.35797495,  0.43713935,  0.63435423, ...,  0.        ,\n",
       "        -0.11508707,  1.2798168 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9970cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2b7d4",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d04d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(6,input_shape=(None,356,28),activation='softmax'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(3,activation=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bec9a",
   "metadata": {},
   "source": [
    "- Sequential specifies the sequence to create models, output of the previous model is input of the next one\n",
    "- model.add adds layers to the neural network. - \n",
    "- input_shape: shape of array\n",
    "- Dense is used to specify the fully connected layer. The arguments of Dense are output dimension from the first case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e865eca",
   "metadata": {},
   "source": [
    "actiavtion\n",
    "-   relu\n",
    "-   sigmiod - used when output needs to be binary\n",
    "-   softmax - used for multiclass classification\n",
    "-   tanh - used when the output needs to be -ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a9ef18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='MeanSquaredError',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a9293",
   "metadata": {},
   "source": [
    "optimizer-  an important process which optimize the input weights by comparing the prediction and the loss function\n",
    "- SGD − Stochastic gradient descent optimizer\n",
    "- RMSprop − RMSProp optimizer.\n",
    "- Adagrad − Adagrad optimizer\n",
    "- Adadelta − Adadelta optimizer.\n",
    "- Adam − Adam optimizer\n",
    "- Adamax − Adamax optimizer from Adam\n",
    "- Nadam − Nesterov Adam optimizer\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd36fda",
   "metadata": {},
   "source": [
    "Loss function is used to find error or deviation in the learning process. Keras requires loss function during model compilation process\n",
    "- mean_squared_error\n",
    "- mean_absolute_error\n",
    "- mean_absolute_percentage_error\n",
    "- mean_squared_logarithmic_error\n",
    "- squared_hinge\n",
    "- hinge\n",
    "- categorical_hinge\n",
    "- logcosh\n",
    "- huber_loss\n",
    "- categorical_crossentropy\n",
    "- sparse_categorical_crossentropy\n",
    "- binary_crossentropy\n",
    "- kullback_leibler_divergence\n",
    "- poisson\n",
    "- cosine_proximity\n",
    "- is_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b5f5e",
   "metadata": {},
   "source": [
    "metrics\n",
    "- accuracy\n",
    "- binary_accuracy\n",
    "- categorical_accuracy\n",
    "- sparse_categorical_accuracy\n",
    "- top_k_categorical_accuracy\n",
    "- sparse_top_k_categorical_accuracy\n",
    "- cosine_proximity\n",
    "- clone_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb0a2216",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "12/12 [==============================] - 25s 8ms/step - loss: 0.6723 - accuracy: 0.7303\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6254 - accuracy: 0.7303\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5834 - accuracy: 0.7303\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7303\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7303\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.7303\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.7303\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.7303\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.7303\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.7303\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.7303\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.7303\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.7303\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.7303\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2592 - accuracy: 0.7303\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.7303\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.7303\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.7303\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.7275\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.7022\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.6573\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2095 - accuracy: 0.6039\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2049 - accuracy: 0.5787\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.5449\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.5169\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1940 - accuracy: 0.4747\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.4410\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1884 - accuracy: 0.4298\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1859 - accuracy: 0.4017\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.3820\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.3764\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.3652\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.3596\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.3371\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.3315\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.3315\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.3315\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1718 - accuracy: 0.3371\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.3399\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.3287\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1688 - accuracy: 0.3371\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.3483\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.3399\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.3511\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.3399\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.3399\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.3596\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.3792\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1626 - accuracy: 0.3961\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.3876\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.4129\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1605 - accuracy: 0.4410\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.4382\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.4551\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.4691\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.4747\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.4775\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.4860\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.4831\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1543 - accuracy: 0.4888\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1534 - accuracy: 0.4972\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.5056\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.5028\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.5028\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.5028\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.5253\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.5421\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.5449\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.5365\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.5281\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.5000\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.4916\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.4944\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.4944\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1402 - accuracy: 0.4944\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1364 - accuracy: 0.5084\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.5084\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.5028\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.5112\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.5140\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.5112\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.4972\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1291 - accuracy: 0.4916\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.4972\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.4972\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.5225\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.5225\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.5197\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.5281\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.5309\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.5365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21bee505310>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce769c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the input data-> X_train, labels-> y_train, number of epochs(iterations), and batch size. \n",
    "#It returns the history of model training. History consists of model accuracy and losses after each epoch.\n",
    "#Usually, the dataset is very big and we cannot fit complete data at once so we use batch size. \n",
    "#This divides our data into batches each of size equal to batch_size. \n",
    "#Now only this number of samples will be loaded into memory and processed. \n",
    "#Once we are done with one batch it is flushed from memory and the next batch will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "614cd3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_81_input'), name='dense_81_input', description=\"created by layer 'dense_81_input'\"), but it was called on an input with incompatible shape (None, 28).\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bc00cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79284704, 0.8233594 , 0.81572664],\n",
       "       [0.5044646 , 0.35347575, 0.35438114],\n",
       "       [0.93753636, 1.0416961 , 1.0319335 ],\n",
       "       ...,\n",
       "       [0.7469493 , 0.7262085 , 0.7543384 ],\n",
       "       [0.7572172 , 0.7401031 , 0.747509  ],\n",
       "       [0.67075205, 0.6851857 , 0.64771795]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dfb0a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "5/5 [==============================] - 2s 30ms/step - loss: 0.1134 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11337263882160187, 0.3333333432674408]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "514d34ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94520724, 0.9449835 , 0.9365538 ],\n",
       "       [0.86020494, 0.88338435, 0.89026064],\n",
       "       [0.8473259 , 0.8239255 , 0.82388103],\n",
       "       [0.7391275 , 0.6827793 , 0.7530076 ],\n",
       "       [0.8012756 , 0.7283977 , 0.757447  ],\n",
       "       [0.72779006, 0.77544427, 0.77381307],\n",
       "       [0.2606116 , 0.34862027, 0.4105322 ],\n",
       "       [0.59326684, 0.5629519 , 0.6406919 ],\n",
       "       [0.82951874, 0.8610203 , 0.86928767],\n",
       "       [0.8845078 , 0.93544185, 0.9204377 ],\n",
       "       [0.9161729 , 0.9062897 , 0.91217196],\n",
       "       [0.6773977 , 0.6162684 , 0.6956766 ],\n",
       "       [0.8843961 , 0.9282093 , 0.89963114],\n",
       "       [0.81866956, 0.8109156 , 0.8215413 ],\n",
       "       [0.54132617, 0.5194262 , 0.5948346 ],\n",
       "       [0.15555526, 0.14466968, 0.12258084],\n",
       "       [0.7225445 , 0.715765  , 0.77386576],\n",
       "       [0.83992577, 0.8593676 , 0.8605102 ],\n",
       "       [0.8442187 , 0.8752471 , 0.88487196],\n",
       "       [0.7419842 , 0.706632  , 0.74696463],\n",
       "       [0.8173136 , 0.9028778 , 0.87098384],\n",
       "       [1.0668514 , 1.1127771 , 1.0250089 ],\n",
       "       [0.90793484, 0.9313961 , 0.9115165 ],\n",
       "       [1.0567882 , 1.0272446 , 1.019381  ],\n",
       "       [0.8432078 , 0.8210038 , 0.8424285 ],\n",
       "       [0.7991585 , 0.8367764 , 0.857821  ],\n",
       "       [0.87509525, 0.8945091 , 0.83431894],\n",
       "       [0.25044197, 0.28619418, 0.17873518],\n",
       "       [0.77086294, 0.76651275, 0.76983505],\n",
       "       [0.5094114 , 0.4343305 , 0.5740091 ],\n",
       "       [1.1465477 , 1.1124709 , 1.0882698 ],\n",
       "       [0.7977122 , 0.7626082 , 0.7533354 ],\n",
       "       [0.17511187, 0.18021888, 0.19541669],\n",
       "       [0.77695346, 0.90936756, 0.8548508 ],\n",
       "       [0.781533  , 0.8179252 , 0.83790267],\n",
       "       [0.16548476, 0.17440449, 0.06657621],\n",
       "       [1.0660504 , 1.0189815 , 1.001117  ],\n",
       "       [0.9784139 , 1.0425771 , 0.9928492 ],\n",
       "       [0.8011751 , 0.814096  , 0.839873  ],\n",
       "       [0.8956548 , 0.9664618 , 0.9503459 ],\n",
       "       [0.17082275, 0.18617715, 0.06998904],\n",
       "       [0.7941966 , 0.8354275 , 0.8534532 ],\n",
       "       [0.9232427 , 0.9225476 , 0.88529545],\n",
       "       [0.3940245 , 0.38450018, 0.3216187 ],\n",
       "       [1.0825282 , 1.0333223 , 1.0274839 ],\n",
       "       [0.42251706, 0.37959835, 0.41499838],\n",
       "       [1.0143745 , 1.0283197 , 0.9908706 ],\n",
       "       [0.7885096 , 0.75917983, 0.80602586],\n",
       "       [0.8491913 , 0.88909924, 0.8853866 ],\n",
       "       [0.91591644, 0.9741423 , 0.93178   ],\n",
       "       [0.5963981 , 0.65801096, 0.62999654],\n",
       "       [0.77207303, 0.8038626 , 0.82377523],\n",
       "       [0.4165239 , 0.36859244, 0.38638318],\n",
       "       [0.88552904, 0.88491046, 0.86184454],\n",
       "       [0.8228434 , 0.83779085, 0.81204545],\n",
       "       [0.7438241 , 0.70796335, 0.70923364],\n",
       "       [0.29619634, 0.28582263, 0.38596797],\n",
       "       [0.5018091 , 0.5301853 , 0.4980646 ],\n",
       "       [0.95125157, 0.99440515, 0.91832507],\n",
       "       [0.48692858, 0.48134294, 0.51664263],\n",
       "       [0.73864347, 0.8248236 , 0.61295456],\n",
       "       [0.74573433, 0.791595  , 0.7387896 ],\n",
       "       [0.9625739 , 1.032427  , 0.97885996],\n",
       "       [0.94694287, 0.98543346, 0.9525419 ],\n",
       "       [1.0630276 , 1.0119525 , 1.0074834 ],\n",
       "       [0.7884278 , 0.8223579 , 0.82964766],\n",
       "       [1.0616624 , 1.0359089 , 1.0242504 ],\n",
       "       [0.2112384 , 0.2275864 , 0.2883401 ],\n",
       "       [0.86827314, 0.85733414, 0.8451877 ],\n",
       "       [0.6158629 , 0.64675033, 0.61991143],\n",
       "       [0.28534755, 0.32168913, 0.20496911],\n",
       "       [0.7234105 , 0.6735594 , 0.6885944 ],\n",
       "       [0.8461926 , 0.8195741 , 0.82252336],\n",
       "       [0.8640028 , 0.914196  , 0.8852547 ],\n",
       "       [0.7210916 , 0.6519449 , 0.7267212 ],\n",
       "       [0.8245586 , 0.86059976, 0.8475525 ],\n",
       "       [0.8639989 , 0.9350873 , 0.9112348 ],\n",
       "       [0.9382793 , 0.94209707, 0.8995069 ],\n",
       "       [1.0909855 , 1.08961   , 1.0825704 ],\n",
       "       [0.762256  , 0.82687616, 0.79694843],\n",
       "       [1.0397718 , 1.0523727 , 1.0099825 ],\n",
       "       [0.62105936, 0.58073866, 0.6741037 ],\n",
       "       [0.84269404, 0.83452916, 0.8274702 ],\n",
       "       [1.0195457 , 0.98368025, 0.9797234 ],\n",
       "       [0.90122604, 0.91913784, 0.9048234 ],\n",
       "       [0.5904254 , 0.57274127, 0.5981493 ],\n",
       "       [0.7822011 , 0.8233305 , 0.8497877 ],\n",
       "       [0.8314377 , 0.8124913 , 0.804303  ],\n",
       "       [0.5824187 , 0.5394184 , 0.5784044 ],\n",
       "       [0.8415424 , 0.78977954, 0.82037103],\n",
       "       [0.91393405, 0.9721006 , 0.92215306],\n",
       "       [0.407382  , 0.38012502, 0.40192783],\n",
       "       [0.16727006, 0.12090467, 0.06372898],\n",
       "       [0.84651846, 0.9044558 , 0.8726345 ],\n",
       "       [1.0819502 , 1.0312172 , 1.0269147 ],\n",
       "       [0.95866954, 1.0992043 , 1.021053  ],\n",
       "       [0.95627344, 0.9475509 , 0.91056377],\n",
       "       [0.16180371, 0.16628611, 0.06422275],\n",
       "       [0.9059738 , 0.91477215, 0.8849932 ],\n",
       "       [0.93140423, 0.97479403, 0.94322824],\n",
       "       [0.8032844 , 0.8207911 , 0.8415568 ],\n",
       "       [0.18449643, 0.19727771, 0.23036812],\n",
       "       [1.1341524 , 1.1156294 , 1.0901815 ],\n",
       "       [0.64027977, 0.6251445 , 0.7340729 ],\n",
       "       [0.9004502 , 0.88775504, 0.85582334],\n",
       "       [1.1237648 , 1.2312272 , 1.1012784 ],\n",
       "       [0.8487598 , 0.8231144 , 0.8241474 ],\n",
       "       [0.8855165 , 0.8889526 , 0.8558835 ],\n",
       "       [0.7272147 , 0.79683185, 0.82778007],\n",
       "       [1.1705155 , 1.1508787 , 1.1307601 ],\n",
       "       [1.0476948 , 1.0441831 , 1.0243506 ],\n",
       "       [0.79472995, 0.7942971 , 0.7649891 ],\n",
       "       [1.070941  , 1.0812517 , 1.0762925 ],\n",
       "       [0.6100797 , 0.71329904, 0.5953413 ],\n",
       "       [0.8361705 , 0.89036644, 0.8723249 ],\n",
       "       [0.741982  , 0.70621824, 0.7043213 ],\n",
       "       [0.74001575, 0.7009585 , 0.7677167 ],\n",
       "       [0.70281494, 0.70863783, 0.6795826 ],\n",
       "       [0.78574145, 0.8047761 , 0.72205913],\n",
       "       [0.4034726 , 0.36109558, 0.47796917],\n",
       "       [0.9225324 , 0.91608083, 0.87898415],\n",
       "       [0.7160626 , 0.65621233, 0.7364157 ],\n",
       "       [0.97482574, 0.9193133 , 0.904677  ],\n",
       "       [0.13534367, 0.10792992, 0.04730562],\n",
       "       [0.7903457 , 0.7764962 , 0.74307597],\n",
       "       [0.2829086 , 0.21692614, 0.19610286],\n",
       "       [0.9252063 , 0.977754  , 0.94171965],\n",
       "       [0.85246116, 0.8583262 , 0.8510822 ],\n",
       "       [0.554674  , 0.45942596, 0.51799726],\n",
       "       [0.71247214, 0.8301883 , 0.77158767],\n",
       "       [0.7011689 , 0.67462397, 0.7748008 ],\n",
       "       [0.6543282 , 0.67796445, 0.75036895],\n",
       "       [0.904193  , 0.92510974, 0.87619764],\n",
       "       [0.8544137 , 0.846761  , 0.8369818 ],\n",
       "       [0.72861946, 0.6929127 , 0.7092067 ],\n",
       "       [0.13534367, 0.10792992, 0.04730562],\n",
       "       [0.8829367 , 0.9279853 , 0.90698266],\n",
       "       [0.89079934, 0.90717685, 0.8851978 ],\n",
       "       [0.96751666, 0.9794506 , 0.9241973 ],\n",
       "       [0.8343926 , 0.8534243 , 0.83748037],\n",
       "       [0.6577808 , 0.67164075, 0.71351725],\n",
       "       [0.8301877 , 0.8120954 , 0.81142575],\n",
       "       [0.7854401 , 0.7271826 , 0.7697118 ],\n",
       "       [0.5813133 , 0.5333512 , 0.52972513],\n",
       "       [0.7857492 , 0.7594422 , 0.7548658 ],\n",
       "       [0.6850848 , 0.6291456 , 0.7242996 ],\n",
       "       [0.8259431 , 0.8867254 , 0.8649822 ],\n",
       "       [0.28075853, 0.30451983, 0.33833417],\n",
       "       [0.875896  , 0.88298976, 0.8636563 ],\n",
       "       [1.0605869 , 1.0187583 , 1.0134094 ],\n",
       "       [0.7640937 , 0.79735255, 0.818059  ],\n",
       "       [0.75854766, 0.7246468 , 0.71953386],\n",
       "       [0.8193606 , 0.78735185, 0.7830846 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b444a4d",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66812b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_51_input'), name='dense_51_input', description=\"created by layer 'dense_51_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_51_input'), name='dense_51_input', description=\"created by layer 'dense_51_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "12/12 [==============================] - 2s 5ms/step - loss: 0.3143 - accuracy: 0.3483\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3031 - accuracy: 0.3933\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2937 - accuracy: 0.4129\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2854 - accuracy: 0.4438\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.4607\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2707 - accuracy: 0.4888\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2636 - accuracy: 0.5197\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.55 - 0s 6ms/step - loss: 0.2567 - accuracy: 0.5562\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.5758\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2424 - accuracy: 0.5955\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2353 - accuracy: 0.6067\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.6096\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.6292\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.6489\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2095 - accuracy: 0.6601\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2034 - accuracy: 0.6742\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.6770\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1908 - accuracy: 0.6798\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1848 - accuracy: 0.6854\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.6910\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.6882\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1687 - accuracy: 0.6966\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1637 - accuracy: 0.6938\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.6966\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1539 - accuracy: 0.6938\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.6882\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.6854\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.6938\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.6910\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.6882\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1286 - accuracy: 0.6798\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.6770\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 0.6685\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.6601\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.6573\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.6517\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.6433\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.6348\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.6348\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.6264\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.6152\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.6039\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.5927\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.5646\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.5421\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.5393\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.5225\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.4972\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.4916\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.4775\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.4747\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.4635\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.4579\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.4410\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.4326\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.4354\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.4326\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.4298\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.4213\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.4185\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.4213\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.4101\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.4045\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.3989\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.3792\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.3708\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.3567\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.3427\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.3343\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.3343\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.3343\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.3258\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.3174\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.3090\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.3062\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.3034\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.2978\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.2893\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0925 - accuracy: 0.2893\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.2781\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0923 - accuracy: 0.2640\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.2612\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.2500\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.2416\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.2360\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.2303\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.2275\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.2219\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.2219\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.2163\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.2079\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.2107\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.2079\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.2079\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.2051\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 0.2079\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.2107\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.2135\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.2135\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.2135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21be26d5b20>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(6,input_shape=(None,356,28),activation='softmax'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(3,activation=None))\n",
    "model.compile(optimizer='Adamax',loss='logcosh',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b340f45",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04e7ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_75_input'), name='dense_75_input', description=\"created by layer 'dense_75_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_75_input'), name='dense_75_input', description=\"created by layer 'dense_75_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "12/12 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.7163\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6798\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6826\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7163\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7163\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7163\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7191\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7219\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7247\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.7247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21bed2dcfa0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(6,input_shape=(None,356,28),activation='softmax'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(3,activation=None))\n",
    "model.compile(optimizer='Adamax',loss='poisson',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "44b69562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_75_input'), name='dense_75_input', description=\"created by layer 'dense_75_input'\"), but it was called on an input with incompatible shape (None, 28).\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00558e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40f375b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 356, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 356, 28), dtype=tf.float32, name='dense_75_input'), name='dense_75_input', description=\"created by layer 'dense_75_input'\"), but it was called on an input with incompatible shape (None, 28).\n",
      "5/5 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.7255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.7254902124404907]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6991c",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b7ee8a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "25/25 [==============================] - 71s 2s/step - loss: 0.5978 - accuracy: 0.7430 - val_loss: 0.6610 - val_accuracy: 0.6729\n",
      "Epoch 2/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.5763 - accuracy: 0.7430 - val_loss: 0.6621 - val_accuracy: 0.6729\n",
      "Epoch 3/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.5623 - accuracy: 0.7510 - val_loss: 0.6635 - val_accuracy: 0.6636\n",
      "Epoch 4/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.5492 - accuracy: 0.7510 - val_loss: 0.6654 - val_accuracy: 0.6729\n",
      "Epoch 5/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.5372 - accuracy: 0.7510 - val_loss: 0.6634 - val_accuracy: 0.6729\n",
      "Epoch 6/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.5278 - accuracy: 0.7510 - val_loss: 0.6619 - val_accuracy: 0.6822\n",
      "Epoch 7/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.5179 - accuracy: 0.7550 - val_loss: 0.6591 - val_accuracy: 0.6822\n",
      "Epoch 8/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.5103 - accuracy: 0.7590 - val_loss: 0.6583 - val_accuracy: 0.6822\n",
      "Epoch 9/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.5022 - accuracy: 0.7590 - val_loss: 0.6593 - val_accuracy: 0.6822\n",
      "Epoch 10/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.4946 - accuracy: 0.7590 - val_loss: 0.6565 - val_accuracy: 0.6822\n",
      "Epoch 11/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.4872 - accuracy: 0.7590 - val_loss: 0.6564 - val_accuracy: 0.6822\n",
      "Epoch 12/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.4808 - accuracy: 0.7590 - val_loss: 0.6614 - val_accuracy: 0.6822\n",
      "Epoch 13/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.4743 - accuracy: 0.7671 - val_loss: 0.6557 - val_accuracy: 0.7103\n",
      "Epoch 14/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.4684 - accuracy: 0.7711 - val_loss: 0.6592 - val_accuracy: 0.7103\n",
      "Epoch 15/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.4625 - accuracy: 0.7751 - val_loss: 0.6574 - val_accuracy: 0.7103\n",
      "Epoch 16/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.4577 - accuracy: 0.7751 - val_loss: 0.6631 - val_accuracy: 0.7103\n",
      "Epoch 17/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.4525 - accuracy: 0.7751 - val_loss: 0.6573 - val_accuracy: 0.7196\n",
      "Epoch 18/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.4452 - accuracy: 0.7751 - val_loss: 0.6641 - val_accuracy: 0.7196\n",
      "Epoch 19/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.4405 - accuracy: 0.7791 - val_loss: 0.6683 - val_accuracy: 0.7196\n",
      "Epoch 20/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.4351 - accuracy: 0.7831 - val_loss: 0.6646 - val_accuracy: 0.7196\n",
      "Epoch 21/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.4293 - accuracy: 0.7791 - val_loss: 0.6700 - val_accuracy: 0.7196\n",
      "Epoch 22/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.4235 - accuracy: 0.7791 - val_loss: 0.6684 - val_accuracy: 0.7196\n",
      "Epoch 23/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.4183 - accuracy: 0.7791 - val_loss: 0.6740 - val_accuracy: 0.7196\n",
      "Epoch 24/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.4119 - accuracy: 0.7831 - val_loss: 0.6762 - val_accuracy: 0.7290\n",
      "Epoch 25/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.4063 - accuracy: 0.7871 - val_loss: 0.6805 - val_accuracy: 0.7103\n",
      "Epoch 26/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.4007 - accuracy: 0.7871 - val_loss: 0.6808 - val_accuracy: 0.7103\n",
      "Epoch 27/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.3948 - accuracy: 0.8032 - val_loss: 0.6855 - val_accuracy: 0.7196\n",
      "Epoch 28/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.3887 - accuracy: 0.8072 - val_loss: 0.6842 - val_accuracy: 0.7196\n",
      "Epoch 29/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.3834 - accuracy: 0.8112 - val_loss: 0.6853 - val_accuracy: 0.7196\n",
      "Epoch 30/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.3753 - accuracy: 0.8193 - val_loss: 0.6945 - val_accuracy: 0.7103\n",
      "Epoch 31/150\n",
      "25/25 [==============================] - 37s 2s/step - loss: 0.3693 - accuracy: 0.8112 - val_loss: 0.6949 - val_accuracy: 0.7290\n",
      "Epoch 32/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.3635 - accuracy: 0.8072 - val_loss: 0.6974 - val_accuracy: 0.7290\n",
      "Epoch 33/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.3554 - accuracy: 0.8153 - val_loss: 0.6992 - val_accuracy: 0.7290\n",
      "Epoch 34/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.3492 - accuracy: 0.8193 - val_loss: 0.7104 - val_accuracy: 0.7290\n",
      "Epoch 35/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.3444 - accuracy: 0.8233 - val_loss: 0.7117 - val_accuracy: 0.7290\n",
      "Epoch 36/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.3384 - accuracy: 0.8273 - val_loss: 0.7149 - val_accuracy: 0.7290\n",
      "Epoch 37/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.3309 - accuracy: 0.8394 - val_loss: 0.7159 - val_accuracy: 0.7290\n",
      "Epoch 38/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.3259 - accuracy: 0.8353 - val_loss: 0.7262 - val_accuracy: 0.7290\n",
      "Epoch 39/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.3197 - accuracy: 0.8353 - val_loss: 0.7303 - val_accuracy: 0.7290\n",
      "Epoch 40/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.3163 - accuracy: 0.8594 - val_loss: 0.7352 - val_accuracy: 0.7103\n",
      "Epoch 41/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.3081 - accuracy: 0.8594 - val_loss: 0.7371 - val_accuracy: 0.7196\n",
      "Epoch 42/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.3028 - accuracy: 0.8514 - val_loss: 0.7486 - val_accuracy: 0.7290\n",
      "Epoch 43/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.2962 - accuracy: 0.8635 - val_loss: 0.7518 - val_accuracy: 0.6916\n",
      "Epoch 44/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.2902 - accuracy: 0.8594 - val_loss: 0.7614 - val_accuracy: 0.7290\n",
      "Epoch 45/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.2859 - accuracy: 0.8675 - val_loss: 0.7694 - val_accuracy: 0.7196\n",
      "Epoch 46/150\n",
      "25/25 [==============================] - 37s 2s/step - loss: 0.2798 - accuracy: 0.8675 - val_loss: 0.7756 - val_accuracy: 0.7103\n",
      "Epoch 47/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.2746 - accuracy: 0.8675 - val_loss: 0.7764 - val_accuracy: 0.7009\n",
      "Epoch 48/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.2684 - accuracy: 0.8835 - val_loss: 0.7807 - val_accuracy: 0.6916\n",
      "Epoch 49/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.2637 - accuracy: 0.8876 - val_loss: 0.7988 - val_accuracy: 0.7103\n",
      "Epoch 50/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.2559 - accuracy: 0.8916 - val_loss: 0.7952 - val_accuracy: 0.6916\n",
      "Epoch 51/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.2527 - accuracy: 0.8916 - val_loss: 0.8002 - val_accuracy: 0.6916\n",
      "Epoch 52/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.2455 - accuracy: 0.8916 - val_loss: 0.8087 - val_accuracy: 0.6822\n",
      "Epoch 53/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2407 - accuracy: 0.8916 - val_loss: 0.8146 - val_accuracy: 0.6916\n",
      "Epoch 54/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.2366 - accuracy: 0.8996 - val_loss: 0.8150 - val_accuracy: 0.6729\n",
      "Epoch 55/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.2306 - accuracy: 0.8996 - val_loss: 0.8348 - val_accuracy: 0.6822\n",
      "Epoch 56/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.2257 - accuracy: 0.8996 - val_loss: 0.8321 - val_accuracy: 0.6916\n",
      "Epoch 57/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.2214 - accuracy: 0.9076 - val_loss: 0.8344 - val_accuracy: 0.6916\n",
      "Epoch 58/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.2175 - accuracy: 0.9116 - val_loss: 0.8404 - val_accuracy: 0.6916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.2135 - accuracy: 0.9116 - val_loss: 0.8512 - val_accuracy: 0.6916\n",
      "Epoch 60/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.2088 - accuracy: 0.9157 - val_loss: 0.8530 - val_accuracy: 0.6916\n",
      "Epoch 61/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.2049 - accuracy: 0.9237 - val_loss: 0.8677 - val_accuracy: 0.6636\n",
      "Epoch 62/150\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2009 - accuracy: 0.9157 - val_loss: 0.8678 - val_accuracy: 0.6822\n",
      "Epoch 63/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.1951 - accuracy: 0.9357 - val_loss: 0.8659 - val_accuracy: 0.7009\n",
      "Epoch 64/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.1912 - accuracy: 0.9277 - val_loss: 0.8740 - val_accuracy: 0.7009\n",
      "Epoch 65/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.1875 - accuracy: 0.9277 - val_loss: 0.8821 - val_accuracy: 0.7009\n",
      "Epoch 66/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.1838 - accuracy: 0.9277 - val_loss: 0.8809 - val_accuracy: 0.6916\n",
      "Epoch 67/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.1792 - accuracy: 0.9398 - val_loss: 0.8884 - val_accuracy: 0.7009\n",
      "Epoch 68/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.1753 - accuracy: 0.9478 - val_loss: 0.8976 - val_accuracy: 0.7009\n",
      "Epoch 69/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.1705 - accuracy: 0.9478 - val_loss: 0.9001 - val_accuracy: 0.7009\n",
      "Epoch 70/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.1676 - accuracy: 0.9478 - val_loss: 0.9109 - val_accuracy: 0.7009\n",
      "Epoch 71/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.1646 - accuracy: 0.9438 - val_loss: 0.9086 - val_accuracy: 0.7196\n",
      "Epoch 72/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1601 - accuracy: 0.9598 - val_loss: 0.9138 - val_accuracy: 0.6916\n",
      "Epoch 73/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.1555 - accuracy: 0.9558 - val_loss: 0.9300 - val_accuracy: 0.7103\n",
      "Epoch 74/150\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1515 - accuracy: 0.9558 - val_loss: 0.9301 - val_accuracy: 0.7103\n",
      "Epoch 75/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.1491 - accuracy: 0.9598 - val_loss: 0.9412 - val_accuracy: 0.7009\n",
      "Epoch 76/150\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.1454 - accuracy: 0.9639 - val_loss: 0.9454 - val_accuracy: 0.7009\n",
      "Epoch 77/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.1418 - accuracy: 0.9598 - val_loss: 0.9600 - val_accuracy: 0.7009\n",
      "Epoch 78/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1409 - accuracy: 0.9679 - val_loss: 0.9548 - val_accuracy: 0.7009\n",
      "Epoch 79/150\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.1381 - accuracy: 0.9639 - val_loss: 0.9695 - val_accuracy: 0.7009\n",
      "Epoch 80/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.1347 - accuracy: 0.9719 - val_loss: 0.9759 - val_accuracy: 0.7009\n",
      "Epoch 81/150\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.1312 - accuracy: 0.9719 - val_loss: 0.9779 - val_accuracy: 0.7009\n",
      "Epoch 82/150\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.1271 - accuracy: 0.9799 - val_loss: 0.9896 - val_accuracy: 0.7009\n",
      "Epoch 83/150\n",
      "25/25 [==============================] - 29s 1s/step - loss: 0.1257 - accuracy: 0.9679 - val_loss: 0.9986 - val_accuracy: 0.7009\n",
      "Epoch 84/150\n",
      "25/25 [==============================] - 29s 1s/step - loss: 0.1238 - accuracy: 0.9759 - val_loss: 0.9990 - val_accuracy: 0.7009\n",
      "Epoch 85/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.1206 - accuracy: 0.9719 - val_loss: 1.0064 - val_accuracy: 0.7103\n",
      "Epoch 86/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.1158 - accuracy: 0.9719 - val_loss: 1.0211 - val_accuracy: 0.7103\n",
      "Epoch 87/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1153 - accuracy: 0.9719 - val_loss: 1.0226 - val_accuracy: 0.7103\n",
      "Epoch 88/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.1156 - accuracy: 0.9799 - val_loss: 1.0276 - val_accuracy: 0.7103\n",
      "Epoch 89/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1088 - accuracy: 0.9759 - val_loss: 1.0407 - val_accuracy: 0.7103\n",
      "Epoch 90/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.1084 - accuracy: 0.9799 - val_loss: 1.0386 - val_accuracy: 0.7196\n",
      "Epoch 91/150\n",
      "25/25 [==============================] - 36s 2s/step - loss: 0.1040 - accuracy: 0.9839 - val_loss: 1.0568 - val_accuracy: 0.7103\n",
      "Epoch 92/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.1042 - accuracy: 0.9759 - val_loss: 1.0535 - val_accuracy: 0.7196\n",
      "Epoch 93/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1009 - accuracy: 0.9839 - val_loss: 1.0688 - val_accuracy: 0.7103\n",
      "Epoch 94/150\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.0981 - accuracy: 0.9799 - val_loss: 1.0619 - val_accuracy: 0.7196\n",
      "Epoch 95/150\n",
      "25/25 [==============================] - 29s 1s/step - loss: 0.0966 - accuracy: 0.9799 - val_loss: 1.0738 - val_accuracy: 0.7196\n",
      "Epoch 96/150\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0947 - accuracy: 0.9880 - val_loss: 1.0809 - val_accuracy: 0.7196\n",
      "Epoch 97/150\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.0933 - accuracy: 0.9920 - val_loss: 1.0870 - val_accuracy: 0.7196\n",
      "Epoch 98/150\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.0941 - accuracy: 0.9799 - val_loss: 1.0916 - val_accuracy: 0.7196\n",
      "Epoch 99/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.0891 - accuracy: 0.9920 - val_loss: 1.0925 - val_accuracy: 0.7196\n",
      "Epoch 100/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0907 - accuracy: 0.9759 - val_loss: 1.1131 - val_accuracy: 0.7196\n",
      "Epoch 101/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0864 - accuracy: 0.9880 - val_loss: 1.1046 - val_accuracy: 0.7196\n",
      "Epoch 102/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.0839 - accuracy: 0.9880 - val_loss: 1.1159 - val_accuracy: 0.7196\n",
      "Epoch 103/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.0826 - accuracy: 0.9839 - val_loss: 1.1210 - val_accuracy: 0.7196\n",
      "Epoch 104/150\n",
      "25/25 [==============================] - 36s 2s/step - loss: 0.0822 - accuracy: 0.9839 - val_loss: 1.1269 - val_accuracy: 0.7196\n",
      "Epoch 105/150\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0792 - accuracy: 0.9880 - val_loss: 1.1302 - val_accuracy: 0.7196\n",
      "Epoch 106/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0820 - accuracy: 0.9880 - val_loss: 1.1373 - val_accuracy: 0.7196\n",
      "Epoch 107/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.0768 - accuracy: 0.9839 - val_loss: 1.1395 - val_accuracy: 0.7196\n",
      "Epoch 108/150\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0769 - accuracy: 0.9880 - val_loss: 1.1534 - val_accuracy: 0.7196\n",
      "Epoch 109/150\n",
      "25/25 [==============================] - 29s 1s/step - loss: 0.0750 - accuracy: 0.9880 - val_loss: 1.1555 - val_accuracy: 0.7196\n",
      "Epoch 110/150\n",
      "25/25 [==============================] - 34s 1s/step - loss: 0.0731 - accuracy: 0.9920 - val_loss: 1.1580 - val_accuracy: 0.7196\n",
      "Epoch 111/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.0708 - accuracy: 0.9880 - val_loss: 1.1697 - val_accuracy: 0.7196\n",
      "Epoch 112/150\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.0690 - accuracy: 0.9880 - val_loss: 1.1670 - val_accuracy: 0.7196\n",
      "Epoch 113/150\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0687 - accuracy: 0.9880 - val_loss: 1.1778 - val_accuracy: 0.7196\n",
      "Epoch 114/150\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.0679 - accuracy: 0.9839 - val_loss: 1.1807 - val_accuracy: 0.7196\n",
      "Epoch 115/150\n",
      "25/25 [==============================] - 47s 2s/step - loss: 0.0651 - accuracy: 0.9920 - val_loss: 1.1847 - val_accuracy: 0.7196\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 34s 1s/step - loss: 0.0649 - accuracy: 0.9960 - val_loss: 1.1906 - val_accuracy: 0.7196\n",
      "Epoch 117/150\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0628 - accuracy: 0.9880 - val_loss: 1.1913 - val_accuracy: 0.7196\n",
      "Epoch 118/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.0620 - accuracy: 0.9960 - val_loss: 1.1988 - val_accuracy: 0.7196\n",
      "Epoch 119/150\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.0608 - accuracy: 0.9960 - val_loss: 1.2094 - val_accuracy: 0.7290\n",
      "Epoch 120/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.0593 - accuracy: 0.9960 - val_loss: 1.2108 - val_accuracy: 0.7196\n",
      "Epoch 121/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.0595 - accuracy: 0.9920 - val_loss: 1.2179 - val_accuracy: 0.7383\n",
      "Epoch 122/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0615 - accuracy: 0.9920 - val_loss: 1.2362 - val_accuracy: 0.7290\n",
      "Epoch 123/150\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.0559 - accuracy: 0.9880 - val_loss: 1.2281 - val_accuracy: 0.7383\n",
      "Epoch 124/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0576 - accuracy: 0.9920 - val_loss: 1.2316 - val_accuracy: 0.7383\n",
      "Epoch 125/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0603 - accuracy: 0.9880 - val_loss: 1.2310 - val_accuracy: 0.7383\n",
      "Epoch 126/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0526 - accuracy: 0.9960 - val_loss: 1.2424 - val_accuracy: 0.7383\n",
      "Epoch 127/150\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.0526 - accuracy: 0.9960 - val_loss: 1.2493 - val_accuracy: 0.7477\n",
      "Epoch 128/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0508 - accuracy: 0.9960 - val_loss: 1.2567 - val_accuracy: 0.7477\n",
      "Epoch 129/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.0514 - accuracy: 0.9920 - val_loss: 1.2545 - val_accuracy: 0.7477\n",
      "Epoch 130/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0510 - accuracy: 0.9880 - val_loss: 1.2620 - val_accuracy: 0.7477\n",
      "Epoch 131/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0485 - accuracy: 0.9920 - val_loss: 1.2593 - val_accuracy: 0.7383\n",
      "Epoch 132/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.0528 - accuracy: 0.9920 - val_loss: 1.2781 - val_accuracy: 0.7477\n",
      "Epoch 133/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.0450 - accuracy: 0.9960 - val_loss: 1.2737 - val_accuracy: 0.7477\n",
      "Epoch 134/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.0458 - accuracy: 0.9960 - val_loss: 1.2842 - val_accuracy: 0.7477\n",
      "Epoch 135/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.0435 - accuracy: 0.9960 - val_loss: 1.2959 - val_accuracy: 0.7477\n",
      "Epoch 136/150\n",
      "25/25 [==============================] - 37s 2s/step - loss: 0.0444 - accuracy: 0.9920 - val_loss: 1.3005 - val_accuracy: 0.7477\n",
      "Epoch 137/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0450 - accuracy: 0.9920 - val_loss: 1.2919 - val_accuracy: 0.7477\n",
      "Epoch 138/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0426 - accuracy: 0.9960 - val_loss: 1.3033 - val_accuracy: 0.7477\n",
      "Epoch 139/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.0413 - accuracy: 0.9960 - val_loss: 1.3105 - val_accuracy: 0.7383\n",
      "Epoch 140/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0403 - accuracy: 0.9960 - val_loss: 1.3173 - val_accuracy: 0.7477\n",
      "Epoch 141/150\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0415 - accuracy: 0.9920 - val_loss: 1.3091 - val_accuracy: 0.7477\n",
      "Epoch 142/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0387 - accuracy: 0.9960 - val_loss: 1.3220 - val_accuracy: 0.7477\n",
      "Epoch 143/150\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.0381 - accuracy: 0.9960 - val_loss: 1.3268 - val_accuracy: 0.7570\n",
      "Epoch 144/150\n",
      "25/25 [==============================] - 37s 2s/step - loss: 0.0372 - accuracy: 0.9960 - val_loss: 1.3352 - val_accuracy: 0.7477\n",
      "Epoch 145/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.0373 - accuracy: 0.9960 - val_loss: 1.3320 - val_accuracy: 0.7570\n",
      "Epoch 146/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.0357 - accuracy: 0.9960 - val_loss: 1.3497 - val_accuracy: 0.7570\n",
      "Epoch 147/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.0347 - accuracy: 0.9960 - val_loss: 1.3432 - val_accuracy: 0.7477\n",
      "Epoch 148/150\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.0350 - accuracy: 0.9960 - val_loss: 1.3449 - val_accuracy: 0.7570\n",
      "Epoch 149/150\n",
      "25/25 [==============================] - 41s 2s/step - loss: 0.0339 - accuracy: 0.9960 - val_loss: 1.3604 - val_accuracy: 0.7570\n",
      "Epoch 150/150\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.0323 - accuracy: 0.9960 - val_loss: 1.3643 - val_accuracy: 0.7570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21bef908e20>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=28, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7a609d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 57s 5ms/step - loss: 1.0000 - accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9999776482582092, 0.8888888955116272]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2df6f2",
   "metadata": {},
   "source": [
    "Model 4 has the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7efe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe377fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc51da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a2610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383656e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
